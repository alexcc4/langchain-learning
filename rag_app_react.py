import sys
import re

from dotenv import load_dotenv
from langchain_ollama import ChatOllama, OllamaEmbeddings
from langchain_chroma import Chroma

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ç¡®ä¿æ ‡å‡†è¾“å‡ºä½¿ç”¨ UTF-8 ç¼–ç 
sys.stdout.reconfigure(encoding='utf-8')

# é…ç½®
CHROMA_PATH = "./chroma_data"
COLLECTION_NAME = "xiyouji_collection"
EMBEDDING_MODEL = "qwen3-embedding:latest"  
CHAT_MODEL = "qwen3:latest"  

# åˆå§‹åŒ– LLM
llm = ChatOllama(
    model=CHAT_MODEL,
    temperature=0.1,
)

# è·å–å‘é‡å­˜å‚¨
embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL)
vector_store = Chroma(
    collection_name=COLLECTION_NAME,
    embedding_function=embeddings,
    persist_directory=CHROMA_PATH,
)
retriever = vector_store.as_retriever(search_kwargs={"k": 3})


# ============= ReAct Prompt =============

REACT_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä½¿ç”¨ ReAct (Reasoning and Acting) æ–¹æ³•çš„è¥¿æ¸¸è®°é—®ç­”åŠ©æ‰‹ã€‚

ä½ éœ€è¦é€šè¿‡ä»¥ä¸‹å¾ªç¯æ¥å›ç­”é—®é¢˜ï¼š
Thoughtï¼ˆæ€è€ƒï¼‰â†’ Actionï¼ˆè¡ŒåŠ¨ï¼‰â†’ Observationï¼ˆè§‚å¯Ÿï¼‰â†’ ... â†’ Answerï¼ˆæœ€ç»ˆç­”æ¡ˆï¼‰

**å¯ç”¨çš„å·¥å…·ï¼š**
- retrieve: ä»è¥¿æ¸¸è®°åŸæ–‡ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ã€‚è¾“å…¥åº”è¯¥æ˜¯æœç´¢æŸ¥è¯¢ã€‚

**è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**
æ¯ä¸€æ­¥å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ä¹‹ä¸€è¾“å‡ºï¼š

1. éœ€è¦æ£€ç´¢æ—¶ï¼š
Thought: [ä½ çš„æ¨ç†è¿‡ç¨‹ï¼Œè§£é‡Šä¸ºä»€ä¹ˆéœ€è¦æ£€ç´¢ä»¥åŠæ£€ç´¢ä»€ä¹ˆ]
Action: retrieve
Action Input: [å…·ä½“çš„æœç´¢æŸ¥è¯¢]

2. å¾—å‡ºæœ€ç»ˆç­”æ¡ˆæ—¶ï¼š
Thought: [ä½ çš„æ¨ç†è¿‡ç¨‹ï¼Œè¯´æ˜ä¸ºä»€ä¹ˆå¯ä»¥ç»™å‡ºç­”æ¡ˆäº†]
Answer: [æœ€ç»ˆç­”æ¡ˆï¼Œç®€æ´æ˜äº†ï¼Œæœ€å¤šä¸‰å¥è¯]

**é‡è¦è§„åˆ™ï¼š**
- æ¯æ¬¡åªèƒ½è¾“å‡ºä¸€ä¸ª Thoughtï¼Œç„¶åæ˜¯ä¸€ä¸ª Action æˆ– Answer
- å¦‚æœé€‰æ‹© Actionï¼Œå¿…é¡»ç­‰å¾… Observation ç»“æœ
- æ”¶åˆ° Observation åï¼Œç»§ç»­ä¸‹ä¸€ä¸ª Thought
- æœ€å¤šè¿›è¡Œ 5 æ¬¡ Actionï¼Œä¹‹åå¿…é¡»ç»™å‡º Answer
- Answer å¿…é¡»åŸºäº Observation çš„å†…å®¹ï¼Œå¦‚æœä¿¡æ¯ä¸è¶³å°±è¯´ä¸çŸ¥é“

**é—®é¢˜ï¼š** {question}

{history}

å¼€å§‹ï¼"""


# ============= å·¥å…·æ‰§è¡Œ =============

def retrieve(query: str) -> str:
    """ä»è¥¿æ¸¸è®°ä¸­æ£€ç´¢ä¿¡æ¯"""
    docs = retriever.invoke(query)
    if not docs:
        return "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
    
    context = "\n\n".join([f"[ç‰‡æ®µ {i+1}]\n{doc.page_content}" for i, doc in enumerate(docs)])
    return context


# ============= ReAct å¾ªç¯ =============

def parse_react_output(text: str) -> tuple[str, str, str]:
    """
    è§£æ ReAct è¾“å‡º
    è¿”å›: (thought, action, action_input) æˆ– (thought, "answer", answer_text)
    """
    text = text.strip()
    
    # æå– Thought
    thought_match = re.search(r'Thought:\s*(.+?)(?=\n(?:Action|Answer):|$)', text, re.DOTALL)
    thought = thought_match.group(1).strip() if thought_match else ""
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆç­”æ¡ˆ
    answer_match = re.search(r'Answer:\s*(.+)', text, re.DOTALL)
    if answer_match:
        return thought, "answer", answer_match.group(1).strip()
    
    # æå– Action
    action_match = re.search(r'Action:\s*(\w+)', text)
    action = action_match.group(1).strip() if action_match else ""
    
    # æå– Action Input
    action_input_match = re.search(r'Action Input:\s*(.+?)(?=\n|$)', text, re.DOTALL)
    action_input = action_input_match.group(1).strip() if action_input_match else ""
    
    return thought, action, action_input


def react_agent(question: str, max_steps: int = 5, verbose: bool = True):
    """ReAct Agent ä¸»å¾ªç¯"""
    
    history = ""
    
    for step in range(max_steps):
        if verbose:
            print(f"\n{'='*60}")
            print(f"ğŸ”„ ç¬¬ {step + 1} æ­¥")
            print(f"{'='*60}")
        
        # 1. LLM ç”Ÿæˆ Thought + Action/Answer
        prompt = REACT_PROMPT.format(question=question, history=history)
        response = llm.invoke([{"role": "user", "content": prompt}])
        output = response.content
        
        if verbose:
            print(f"\nğŸ¤– LLM è¾“å‡º:\n{output}")
        
        # 2. è§£æè¾“å‡º
        thought, action, action_input = parse_react_output(output)
        
        if not thought:
            if verbose:
                print("\nâš ï¸  è­¦å‘Šï¼šæ— æ³•è§£æ Thoughtï¼Œé‡è¯•...")
            continue
        
        # 3. å¦‚æœæ˜¯æœ€ç»ˆç­”æ¡ˆï¼Œè¿”å›
        if action == "answer":
            if verbose:
                print(f"\nğŸ’¡ æ€è€ƒ: {thought}")
                print(f"\nâœ… æœ€ç»ˆç­”æ¡ˆ:\n{action_input}")
            return action_input
        
        # 4. æ‰§è¡Œ Action
        if action == "retrieve":
            if verbose:
                print(f"\nğŸ’¡ æ€è€ƒ: {thought}")
                print(f"\nğŸ” æ‰§è¡Œæ£€ç´¢: {action_input}")
            
            observation = retrieve(action_input)
            
            if verbose:
                print(f"\nğŸ“š è§‚å¯Ÿç»“æœ:\n{observation[:300]}..." if len(observation) > 300 else f"\nğŸ“š è§‚å¯Ÿç»“æœ:\n{observation}")
            
            # 5. æ›´æ–°å†å²
            history += f"\nThought: {thought}\nAction: {action}\nAction Input: {action_input}\nObservation: {observation}\n"
        else:
            if verbose:
                print(f"\nâš ï¸  æœªçŸ¥çš„ Action: {action}")
            history += f"\nThought: {thought}\n[é”™è¯¯ï¼šæœªçŸ¥çš„ Action '{action}']\n"
    
    # è¾¾åˆ°æœ€å¤§æ­¥æ•°
    if verbose:
        print(f"\nâš ï¸  å·²è¾¾åˆ°æœ€å¤§æ­¥æ•° ({max_steps})ï¼Œå¼ºåˆ¶ç”Ÿæˆç­”æ¡ˆ...")
    
    final_prompt = REACT_PROMPT.format(
        question=question, 
        history=history + "\nä½ å¿…é¡»ç°åœ¨ç»™å‡ºæœ€ç»ˆç­”æ¡ˆï¼ˆä½¿ç”¨ Answer: æ ¼å¼ï¼‰"
    )
    response = llm.invoke([{"role": "user", "content": final_prompt}])
    thought, action, answer = parse_react_output(response.content)
    
    if action == "answer":
        return answer
    else:
        return "æŠ±æ­‰ï¼Œæ— æ³•åœ¨é™å®šæ­¥éª¤å†…å¾—å‡ºç­”æ¡ˆã€‚"


# ============= ä¸»ç¨‹åº =============

def main():
    print("="*60)
    print("ğŸ§  è¥¿æ¸¸è®° ReAct é—®ç­”ç³»ç»Ÿ")
    print("   (Reasoning and Acting)")
    print("="*60)
    
    # æ£€æŸ¥å‘é‡åº“
    try:
        count = vector_store._collection.count()
        print(f"âœ“ å‘é‡æ•°æ®åº“å·²åŠ è½½: {count} ä¸ªæ–‡æ¡£å—\n")
    except Exception as e:
        print(f"âœ— å‘é‡æ•°æ®åº“åŠ è½½å¤±è´¥: {e}")
        print("è¯·å…ˆè¿è¡Œ main.py ç´¢å¼• PDF æ–‡æ¡£")
        return
    
    # æµ‹è¯•é—®é¢˜
    test_queries = [
        "å­™æ‚Ÿç©ºæ˜¯æ€ä¹ˆå‡ºç”Ÿçš„ï¼Ÿ",
        "å”åƒ§å¸ˆå¾’ä¸€å…±æœ‰å‡ ä¸ªäººï¼Ÿ",
    ]
    
    for query in test_queries:
        print(f"\n\n{'#'*60}")
        print(f"â“ é—®é¢˜: {query}")
        print(f"{'#'*60}")
        
        answer = react_agent(query, max_steps=5, verbose=True)
        
        print(f"\n{'='*60}")
        print(f"ğŸ“ æœ€ç»ˆç­”æ¡ˆ: {answer}")
        print(f"{'='*60}\n")
    
    # äº¤äº’å¼é—®ç­”
    print(f"\n{'='*60}")
    print("ç°åœ¨å¯ä»¥å¼€å§‹æé—®äº†ï¼ˆè¾“å…¥ 'quit' é€€å‡ºï¼‰ï¼š")
    print(f"{'='*60}\n")
    
    while True:
        try:
            query = input("ä½ çš„é—®é¢˜: ").strip()
            if query.lower() in ['quit', 'exit', 'q', 'é€€å‡º']:
                print("å†è§ï¼")
                break
            if not query:
                continue
            
            print(f"\n{'#'*60}")
            print(f"â“ é—®é¢˜: {query}")
            print(f"{'#'*60}")
            
            answer = react_agent(query, max_steps=5, verbose=True)
            
            print(f"\n{'='*60}")
            print(f"ğŸ“ æœ€ç»ˆç­”æ¡ˆ: {answer}")
            print(f"{'='*60}\n")
            
        except KeyboardInterrupt:
            print("\n\nå†è§ï¼")
            break


if __name__ == "__main__":
    main()

